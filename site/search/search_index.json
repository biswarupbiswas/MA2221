{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"MA2221 \u2013 Foundational Mathematics for Machine Learning","text":""},{"location":"#i-course-information","title":"\u2139\ufe0f Course Information","text":"<p>Instructor: Biswarup Biswas Institution: Mahindra University</p>"},{"location":"#class-schedule","title":"\ud83d\udcc5 Class Schedule","text":"Session Type Day Time Venue Practical Monday 15:35 \u2013 17:30 Computer Lab 3 Lecture Tuesday 09:25 \u2013 10:20 ELT6 Lecture Wednesday 10:35 \u2013 11:30 ELT6 Lecture Thursday 14:35 \u2013 15:30 ELT6"},{"location":"#about-the-course","title":"\ud83c\udfaf About the Course","text":"<p>This course develops a mathematical perspective on machine learning, focusing on how data and models are described using linear algebra, geometry, probability, and optimization. It emphasizes understanding learning as a problem of fitting and approximating functions in high dimensional spaces, while also giving students hands on experience in applying these ideas to real data. The course equips students with the mathematical language and practical insight needed to analyze and use modern machine learning methods in a clear and principled way.</p>"},{"location":"lectures/","title":"\ud83d\udcda Lecture Schedule","text":"No Date Topic Materials 01 20-01-2026 Foundations: Mapping Mathematics to Machine Learning \u23f3 Pending"},{"location":"lectures/#note","title":"\ud83d\udccc Note","text":"<p>Slides will be uploaded after each session.</p>"},{"location":"syllabus/","title":"Mathematics for Machine Learning","text":""},{"location":"syllabus/#part-i-mathematical-foundations","title":"PART I \u2014 Mathematical Foundations","text":""},{"location":"syllabus/#module-1-introduction","title":"Module 1 \u2014 Introduction","text":"<p>Class 1 - Machine learning as function approximation and data fitting - Training, prediction, and model error - Why geometry, probability, and optimization matter  </p>"},{"location":"syllabus/#module-2-linear-algebra-for-data","title":"Module 2 \u2014 Linear Algebra for Data","text":"<p>Class 2 \u2013 Vectors and data representation in high dimensions Class 3 \u2013 Linear maps as feature transformations Class 4 \u2013 Rank, conditioning, and stability of models Class 5 \u2013 Subspaces as hypothesis spaces Class 6 \u2013 Basis change and coordinate systems Class 7 \u2013 Null spaces and information loss Class 8 \u2013 Geometry of linear transformations  </p>"},{"location":"syllabus/#module-3-analytic-geometry-of-data","title":"Module 3 \u2014 Analytic Geometry of Data","text":"<p>Class 9 \u2013 Norms, distances, and similarity measures Class 10 \u2013 Inner products and cosine similarity Class 11 \u2013 Orthogonality and decorrelation Class 12 \u2013 Projections and least-squares fitting Class 13 \u2013 Geometry of data clouds  </p>"},{"location":"syllabus/#module-4-matrix-decompositions","title":"Module 4 \u2014 Matrix Decompositions","text":"<p>Class 14 \u2013 Linear operators and invariant directions Class 15 \u2013 Eigenvalues and eigenvectors Class 16 \u2013 Symmetric matrices and quadratic forms Class 17 \u2013 Singular Value Decomposition (SVD) Class 18 \u2013 SVD for optimal low-rank data representation  </p>"},{"location":"syllabus/#module-5-vector-calculus-for-learning","title":"Module 5 \u2014 Vector Calculus for Learning","text":"<p>Class 19 \u2013 Multivariate functions and loss surfaces Class 20 \u2013 Gradients as directions of steepest descent Class 21 \u2013 Hessians, curvature, and conditioning Class 22 \u2013 Gradient-based optimization  </p>"},{"location":"syllabus/#module-6-probability-for-data","title":"Module 6 \u2014 Probability for Data","text":"<p>Class 23 \u2013 Random variables as data generators Class 24 \u2013 Mean, variance, and covariance Class 25 \u2013 Multivariate Gaussian distributions Class 26 \u2013 Probability as a model of uncertainty  </p>"},{"location":"syllabus/#part-ii-core-machine-learning","title":"PART II \u2014 Core Machine Learning","text":""},{"location":"syllabus/#module-7-when-models-meet-data","title":"Module 7 \u2014 When Models Meet Data","text":"<p>Class 27 \u2013 Training, testing, and generalization Class 28 \u2013 Loss functions and risk minimization Class 29 \u2013 Overfitting, bias\u2013variance, regularization  </p>"},{"location":"syllabus/#module-8-linear-regression","title":"Module 8 \u2014 Linear Regression","text":"<p>Class 30 \u2013 Linear regression as projection Class 31 \u2013 Least-squares and normal equations Class 32 \u2013 Ridge regression and stability  </p>"},{"location":"syllabus/#module-9-principal-component-analysis","title":"Module 9 \u2014 Principal Component Analysis","text":"<p>Class 33 \u2013 Variance, covariance, and principal directions Class 34 \u2013 Eigenvectors as principal components Class 35 \u2013 PCA via SVD Class 36 \u2013 Data compression and visualization  </p>"},{"location":"syllabus/#module-10-gaussian-mixture-models","title":"Module 10 \u2014 Gaussian Mixture Models","text":"<p>Class 37 \u2013 Probabilistic clustering and mixture models Class 38 \u2013 Gaussian mixtures Class 39 \u2013 Expectation\u2013Maximization (EM) algorithm  </p>"},{"location":"syllabus/#module-11-support-vector-machines","title":"Module 11 \u2014 Support Vector Machines","text":"<p>Class 40 \u2013 Maximum margin classification and separating hyperplanes Class 41 \u2013 Dual formulation and support vectors Class 42 \u2013 Kernel methods and nonlinear decision boundaries  </p>"},{"location":"syllabus/#textbook","title":"Textbook","text":"<p>Deisenroth, M. P., Faisal, A. A., &amp; Ong, C. S. (2020). Mathematics for Machine Learning. Cambridge University Press.</p>"},{"location":"tutorials/","title":"\u270d\ufe0f Tutorial Sheets","text":"No Release Date Topic Download \u2014 \u2014 Coming Soon \u2014"},{"location":"tutorials/#instructions","title":"\ud83d\udee0\ufe0f Instructions","text":"<ul> <li>Tutorial sheets should be solved prior to the weekly lab.</li> </ul>"}]}